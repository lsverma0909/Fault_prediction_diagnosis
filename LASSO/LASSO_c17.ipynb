{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NidOC8S5riYp"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbCYhiRdnFar",
        "outputId": "d4fa27ee-b156-42da-8316-66c162c26498"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/content/drive/My Drive/circuits/c17.test'"
      ],
      "metadata": {
        "id": "siRAqCl9nNG7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Reproducibility ------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# ------------------ Expand Don't Care ------------------\n",
        "def expand_dont_care(pattern):\n",
        "    chars = [(c if c in '01' else ['0', '1']) for c in pattern]\n",
        "    chars = [(c if isinstance(c, list) else [c]) for c in chars]\n",
        "    return [''.join(bits) for bits in itertools.product(*chars)]\n",
        "\n",
        "# ------------------ Parse .test File ------------------\n",
        "def parse_isc_file(filepath):\n",
        "    combo_to_faults = defaultdict(set)\n",
        "    fault_to_combos = defaultdict(list)\n",
        "    current_fault = None\n",
        "\n",
        "    with open(filepath, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if not line or line.startswith(\"*\"):\n",
        "                continue\n",
        "            if '/' in line:\n",
        "                parts = line.split(\"/\")\n",
        "                fault = parts[0].strip().replace(\"->\", \"_\") + \"/\" + parts[1].strip()\n",
        "                current_fault = fault\n",
        "            elif ':' in line and current_fault:\n",
        "                parts = line.split(\":\")[1].strip().split()\n",
        "                input_pattern = parts[0]\n",
        "                output_pattern = parts[1] if len(parts) > 1 else \"\"\n",
        "                input_expanded = expand_dont_care(input_pattern)\n",
        "                output_expanded = expand_dont_care(output_pattern)\n",
        "                for xi in input_expanded:\n",
        "                    for yo in output_expanded:\n",
        "                        combined = xi + yo\n",
        "                        combo_to_faults[combined].add(current_fault)\n",
        "                        fault_to_combos[current_fault].append(combined)\n",
        "    return combo_to_faults, fault_to_combos\n",
        "\n",
        "# ------------------ Dataset Builder ------------------\n",
        "def build_multilabel_dataset(combo_to_faults):\n",
        "    all_faults = sorted({f for faults in combo_to_faults.values() for f in faults})\n",
        "    fault_index = {fault: idx for idx, fault in enumerate(all_faults)}\n",
        "    dataset = []\n",
        "    for combo, faults in combo_to_faults.items():\n",
        "        label_vector = [0] * len(all_faults)\n",
        "        for fault in faults:\n",
        "            label_vector[fault_index[fault]] = 1\n",
        "        features = [int(bit) for bit in combo]\n",
        "        dataset.append((features, label_vector))\n",
        "    return dataset, fault_index"
      ],
      "metadata": {
        "id": "vUnMkUmHnIfG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Load and Prepare ------------------\n",
        "combo_to_faults, fault_to_combos = parse_isc_file(test_path)\n",
        "dataset, fault_index = build_multilabel_dataset(combo_to_faults)\n",
        "\n",
        "X = np.array([x for x, _ in dataset])\n",
        "y = np.array([y for _, y in dataset])\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED)"
      ],
      "metadata": {
        "id": "nDxWDjGGnccr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ LASSO Classifier ------------------\n",
        "lasso = OneVsRestClassifier(\n",
        "    LogisticRegression(penalty='l1', solver='saga', max_iter=1000, random_state=SEED)\n",
        ")\n",
        "lasso.fit(X_train, y_train)\n",
        "y_pred = lasso.predict(X_val)\n",
        "\n",
        "# ------------------ Evaluation ------------------\n",
        "f1 = f1_score(y_val, y_pred, average='macro', zero_division=0)\n",
        "overall_acc = (y_val == y_pred).sum() / y_val.size\n",
        "\n",
        "# ------------------ Fault-Type Accuracy ------------------\n",
        "stuck_at_0_indices = [idx for fault, idx in fault_index.items() if fault.endswith('/0')]\n",
        "stuck_at_1_indices = [idx for fault, idx in fault_index.items() if fault.endswith('/1')]\n",
        "\n",
        "def type_accuracy(y_true, y_pred, indices, fault_type):\n",
        "    y_true_type = y_true[:, indices]\n",
        "    y_pred_type = y_pred[:, indices]\n",
        "    correct = (y_true_type == y_pred_type).sum()\n",
        "    total = y_true_type.size\n",
        "    acc = correct / total if total > 0 else 0\n",
        "    print(f\"{fault_type} Accuracy: {acc:.4f} ({correct}/{total})\")\n",
        "    return acc\n",
        "\n",
        "# ------------------ Print Final Metrics ------------------\n",
        "print(f\"\\nValidation F1 Score: {f1:.4f}\")\n",
        "print(f\"Final Overall Accuracy: {overall_acc:.4f} ({(overall_acc * y_val.size):.0f}/{y_val.size})\\n\")\n",
        "print(\"--- Fault-Type Accuracy ---\")\n",
        "type_accuracy(y_val, y_pred, stuck_at_0_indices, \"Stuck-at-0\")\n",
        "type_accuracy(y_val, y_pred, stuck_at_1_indices, \"Stuck-at-1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PruA7KW8mnwd",
        "outputId": "0089b251-d216-4beb-ce03-a7481883a735"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation F1 Score: 0.6449\n",
            "Final Overall Accuracy: 0.9606 (830/864)\n",
            "\n",
            "--- Fault-Type Accuracy ---\n",
            "Stuck-at-0 Accuracy: 0.9259 (200/216)\n",
            "Stuck-at-1 Accuracy: 0.9722 (630/648)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.9722222222222222)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}